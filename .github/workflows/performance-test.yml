name: Performance Test

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    # ë§¤ì¼ ìƒˆë²½ 2ì‹œ UTC (í•œêµ­ì‹œê°„ ì˜¤ì „ 11ì‹œ) ì‹¤í–‰
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Test mode (short/medium/long)'
        required: true
        default: 'short'
        type: choice
        options:
          - short
          - medium
          - long
      seed:
        description: 'Random seed for reproducible tests (default: 20251211)'
        required: false
        default: '20251211'
        type: string

jobs:
  performance-test:
    runs-on: ubuntu-latest
    timeout-minutes: 180 # 3ì‹œê°„

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 10

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build
        run: pnpm run build

      - name: Start server
        run: |
          pnpm run preview &
          echo $! > server.pid
        env:
          PORT: 5173

      - name: Wait for server
        run: pnpm exec wait-on http://localhost:4173 -t 60000

      # PRìš© ì§§ì€ í…ŒìŠ¤íŠ¸ (30ë¶„)
      - name: Run short performance test (PR)
        if: github.event_name == 'pull_request'
        run: pnpm run test:perf:short --seed=${{ github.event.inputs.seed || '20251211' }}
        continue-on-error: true

      # Pushìš© ì¤‘ê°„ í…ŒìŠ¤íŠ¸ (2ì‹œê°„)
      - name: Run medium performance test (Push)
        if: github.event_name == 'push' && github.event.inputs.test_mode != 'long'
        run: pnpm run test:perf:medium --seed=${{ github.event.inputs.seed || '20251211' }}
        continue-on-error: true

      # Nightly ì¥ì‹œê°„ í…ŒìŠ¤íŠ¸ (12ì‹œê°„)
      - name: Run long performance test (Nightly)
        if: github.event_name == 'schedule' || github.event.inputs.test_mode == 'long'
        run: pnpm run test:perf:long --seed=${{ github.event.inputs.seed || '20251211' }}
        continue-on-error: true

      - name: Stop server
        if: always()
        run: |
          if [ -f server.pid ]; then
            kill $(cat server.pid) || true
            rm server.pid
          fi

      - name: Upload metrics artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-metrics-${{ github.run_id }}
          path: test-results/
          retention-days: 30

      # PRì— ê²°ê³¼ ì½”ë©˜íŠ¸
      - name: Comment PR with results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            let summary;
            try {
              summary = JSON.parse(fs.readFileSync('test-results/perf-summary.json', 'utf8'));
            } catch (e) {
              summary = { passed: false, error: 'Results not available' };
            }

            const statusEmoji = (value, warningThreshold, criticalThreshold, lowerIsBetter = false) => {
              if (lowerIsBetter) {
                if (value <= warningThreshold) return 'âœ…';
                if (value <= criticalThreshold) return 'âš ï¸';
                return 'âŒ';
              }
              if (value >= warningThreshold) return 'âœ…';
              if (value >= criticalThreshold) return 'âš ï¸';
              return 'âŒ';
            };

            const body = `## ğŸ“Š Performance Test Results

            | Metric | Value | Status |
            |--------|-------|--------|
            | **Duration** | ${summary.duration || 'N/A'} min | - |
            | **Memory Growth** | ${summary.memoryGrowth || 'N/A'} MB/h | ${statusEmoji(parseFloat(summary.memoryGrowth || 0), 15, 25, true)} |
            | **Avg Render Time** | ${summary.avgRenderTime || 'N/A'} ms | ${statusEmoji(parseFloat(summary.avgRenderTime || 0), 50, 100, true)} |
            | **Avg FPS** | ${summary.avgFps || 'N/A'} | ${statusEmoji(parseFloat(summary.avgFps || 60), 50, 30)} |
            | **Min Health Score** | ${summary.minHealthScore || 'N/A'} | ${statusEmoji(summary.minHealthScore || 100, 70, 40)} |
            | **SLO Violations** | ${summary.sloViolations || 0} | ${summary.sloViolations === 0 ? 'âœ…' : (summary.criticalViolations > 0 ? 'âŒ' : 'âš ï¸')} |

            ### Result: ${summary.passed ? 'âœ… **PASSED**' : 'âŒ **FAILED**'}

            <details>
            <summary>SLO Thresholds</summary>

            | Metric | Warning | Critical |
            |--------|---------|----------|
            | Heap Usage | 60% | 80% |
            | Memory Growth | 20 MB/h | 30 MB/h |
            | Render Time | 50ms | 100ms |
            | FPS | < 50 | < 30 |
            | Health Score | < 50 | < 30 |

            </details>

            ---
            ğŸ¤– Generated by [Performance Test Workflow]
            `;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

      # SLO ê²€ì¦ ìë™í™”
      - name: Verify SLO
        run: |
          if [ -f "test-results/perf-summary.json" ]; then
            npx tsx scripts/verify-slo.ts --ci --verbose test-results/perf-summary.json
          else
            echo "::warning::Performance results not found"
          fi

      # ë² ì´ìŠ¤ë¼ì¸ê³¼ ë¹„êµ (main ë¸Œëœì¹˜ì—ì„œë§Œ)
      - name: Compare with baseline
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          if [ -f "test-results/performance/baseline.json" ] && [ -f "test-results/perf-summary.json" ]; then
            npx tsx scripts/verify-slo.ts --compare test-results/performance/baseline.json test-results/perf-summary.json
          else
            echo "Baseline not available for comparison"
          fi
        continue-on-error: true

  # ë©”íŠ¸ë¦­ ì¶”ì„¸ ì¶”ì  (Nightlyë§Œ)
  track-metrics:
    needs: performance-test
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 10

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'pnpm'

      - name: Download current metrics
        uses: actions/download-artifact@v4
        with:
          name: performance-metrics-${{ github.run_id }}
          path: current-results/

      - name: Analyze trends
        run: |
          echo "ğŸ“ˆ Analyzing performance trends..."
          # ì¶”ì„¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ (ì¶”í›„ êµ¬í˜„)
          # pnpm run analyze:perf-trends

      - name: Send Slack notification on regression
        if: failure()
        uses: slackapi/slack-github-action@v1.25.0
        with:
          payload: |
            {
              "text": "âš ï¸ Performance Regression Detected",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Performance Regression Detected*\n\nThe nightly performance test has detected a regression.\n\n<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Details>"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK

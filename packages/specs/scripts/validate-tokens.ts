/**
 * Token Validation Script
 *
 * í”„ë¦¬ë¯¸í‹°ë¸Œ í† í°ê³¼ ì»´í¬ë„ŒíŠ¸ ìŠ¤í™ì˜ í† í° ì°¸ì¡° ì¼ê´€ì„± ê²€ì¦
 *
 * Usage: pnpm validate:tokens
 */

import { lightColors, darkColors } from '../src/primitives/colors';
import { spacing } from '../src/primitives/spacing';
import { typography } from '../src/primitives/typography';
import { radius } from '../src/primitives/radius';
import { shadows } from '../src/primitives/shadows';
import { resolveToken } from '../src/renderers/utils/tokenResolver';
import { isValidTokenRef, type TokenRef } from '../src/types/token.types';
import type { ComponentSpec, VariantSpec, SizeSpec } from '../src/types';
import * as fs from 'fs/promises';
import * as path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

interface TokenValidationResult {
  passed: boolean;
  totalTokens: number;
  resolvedTokens: number;
  errors: string[];
  warnings: string[];
}

// í”„ë¦¬ë¯¸í‹°ë¸Œì— ì •ì˜ëœ ëª¨ë“  í† í° ì´ë¦„ ìˆ˜ì§‘
function collectPrimitiveTokens(): Map<string, Set<string>> {
  const tokens = new Map<string, Set<string>>();
  tokens.set('color', new Set(Object.keys(lightColors)));
  tokens.set('spacing', new Set(Object.keys(spacing)));
  tokens.set('typography', new Set(Object.keys(typography)));
  tokens.set('radius', new Set(Object.keys(radius)));
  tokens.set('shadow', new Set(Object.keys(shadows)));
  return tokens;
}

// í† í° ì°¸ì¡°ì—ì„œ ì¹´í…Œê³ ë¦¬ì™€ ì´ë¦„ ì¶”ì¶œ
function parseTokenRef(ref: string): { category: string; name: string } | null {
  const match = ref.match(/^\{(\w+)\.(.+)\}$/);
  if (!match) return null;
  return { category: match[1], name: match[2] };
}

// ìŠ¤í™ì—ì„œ ì‚¬ìš©ëœ ëª¨ë“  í† í° ì°¸ì¡° ì¶”ì¶œ
function extractTokenRefs(spec: ComponentSpec<unknown>): { ref: string; location: string }[] {
  const refs: { ref: string; location: string }[] = [];

  // variants
  Object.entries(spec.variants).forEach(([name, variant]) => {
    const variantRefs: [string, TokenRef | undefined][] = [
      ['background', variant.background],
      ['backgroundHover', variant.backgroundHover],
      ['backgroundPressed', variant.backgroundPressed],
      ['text', variant.text],
      ['textHover', variant.textHover],
      ['border', variant.border],
      ['borderHover', variant.borderHover],
    ];
    for (const [field, ref] of variantRefs) {
      if (ref && typeof ref === 'string' && ref.startsWith('{')) {
        refs.push({ ref, location: `variants.${name}.${field}` });
      }
    }
  });

  // sizes
  Object.entries(spec.sizes).forEach(([name, size]) => {
    refs.push({ ref: size.fontSize, location: `sizes.${name}.fontSize` });
    refs.push({ ref: size.borderRadius, location: `sizes.${name}.borderRadius` });
  });

  return refs;
}

async function main(): Promise<void> {
  console.log('ğŸ” Validating Token References...\n');

  const result: TokenValidationResult = {
    passed: true,
    totalTokens: 0,
    resolvedTokens: 0,
    errors: [],
    warnings: [],
  };

  const primitiveTokens = collectPrimitiveTokens();

  // í”„ë¦¬ë¯¸í‹°ë¸Œ í† í° ìš”ì•½ ì¶œë ¥
  console.log('ğŸ“¦ Primitive Tokens:');
  for (const [category, names] of primitiveTokens) {
    console.log(`   ${category}: ${names.size} tokens`);
  }
  console.log('');

  // ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ìŠ¤í™ ë¡œë“œ
  const componentsDir = path.join(__dirname, '../src/components');
  const files = await fs.readdir(componentsDir).catch(() => []);
  const specFiles = files.filter(f => f.endsWith('.spec.ts'));

  if (specFiles.length === 0) {
    console.log('âš ï¸  No spec files found');
    return;
  }

  for (const file of specFiles) {
    const filePath = path.join(componentsDir, file);
    const module = await import(filePath);
    const specName = file.replace('.spec.ts', '') + 'Spec';
    const spec = module.default || module[specName];

    if (!spec) {
      result.warnings.push(`${file}: No valid spec export found`);
      continue;
    }

    console.log(`  Checking: ${file}`);
    const tokenRefs = extractTokenRefs(spec);

    for (const { ref, location } of tokenRefs) {
      result.totalTokens++;

      // ìœ íš¨ì„± ê²€ì‚¬
      if (!isValidTokenRef(ref)) {
        result.errors.push(`${file}: ${location} â€” invalid token ref: ${ref}`);
        result.passed = false;
        continue;
      }

      // í”„ë¦¬ë¯¸í‹°ë¸Œ ì¡´ì¬ í™•ì¸
      const parsed = parseTokenRef(ref);
      if (!parsed) continue;

      const categoryTokens = primitiveTokens.get(parsed.category);
      if (!categoryTokens) {
        result.errors.push(`${file}: ${location} â€” unknown category: ${parsed.category}`);
        result.passed = false;
        continue;
      }

      if (!categoryTokens.has(parsed.name)) {
        result.errors.push(`${file}: ${location} â€” token "${parsed.name}" not found in ${parsed.category} primitives`);
        result.passed = false;
        continue;
      }

      // resolve ê°€ëŠ¥ í™•ì¸ (light + dark)
      const lightValue = resolveToken(ref as TokenRef, 'light');
      const darkValue = resolveToken(ref as TokenRef, 'dark');

      if (lightValue === ref || darkValue === ref) {
        result.warnings.push(`${file}: ${location} â€” could not resolve: ${ref}`);
      } else {
        result.resolvedTokens++;
      }
    }
  }

  // ê²°ê³¼ ì¶œë ¥
  console.log('\n' + 'â”€'.repeat(50));
  console.log(`\nğŸ“Š Token Validation Summary:`);
  console.log(`   Total references: ${result.totalTokens}`);
  console.log(`   Resolved:         ${result.resolvedTokens}`);
  console.log(`   Failed:           ${result.totalTokens - result.resolvedTokens}`);

  if (result.errors.length > 0) {
    console.log('\nâŒ Errors:');
    result.errors.forEach(e => console.log(`   â€¢ ${e}`));
  }

  if (result.warnings.length > 0) {
    console.log('\nâš ï¸  Warnings:');
    result.warnings.forEach(w => console.log(`   â€¢ ${w}`));
  }

  if (result.passed) {
    console.log('\nâœ… All token references are valid!');
  } else {
    console.log('\nâŒ Token validation failed');
    process.exit(1);
  }
}

main();
